{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb1083a8",
   "metadata": {},
   "source": [
    "<h1><center>Comparison of logistic regression in sklearn and statsmodels</center></h1>\n",
    "<center>Rotten Tomatoes Group</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede3889f",
   "metadata": {},
   "source": [
    "## 1. Setup\n",
    "Using a sample binary classification dataset from sklearn, we can compare the API calls of each logistic regression function. \n",
    "\n",
    "First, load the breast cancer sample dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "6f14f90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from statsmodels.discrete.discrete_model import Logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "134f56df",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "72b98945",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename', 'data_module'])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "4a4c73f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = data['data']\n",
    "y = data['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "eb1c9107",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 30)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "aa14d6c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569,)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "4b195799",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "586ce6d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['mean radius', 'mean texture', 'mean perimeter', 'mean area',\n",
       "       'mean smoothness', 'mean compactness', 'mean concavity',\n",
       "       'mean concave points', 'mean symmetry', 'mean fractal dimension',\n",
       "       'radius error', 'texture error', 'perimeter error', 'area error',\n",
       "       'smoothness error', 'compactness error', 'concavity error',\n",
       "       'concave points error', 'symmetry error',\n",
       "       'fractal dimension error', 'worst radius', 'worst texture',\n",
       "       'worst perimeter', 'worst area', 'worst smoothness',\n",
       "       'worst compactness', 'worst concavity', 'worst concave points',\n",
       "       'worst symmetry', 'worst fractal dimension'], dtype='<U23')"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['feature_names']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d5cf37",
   "metadata": {},
   "source": [
    "We'll simulate our regression problem by picking a single, continuous X feature and using that to predict our binary outcome variable. Let's use \"mean radius\" to predict a diagnosis of breast cancer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "05cde02e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569,)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_radius = features[:, 1]\n",
    "mean_radius.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "fa5f221f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569,)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "2cc84eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Best practice would be to do a train/test split here, but it's not necessary for a demo. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3390474b",
   "metadata": {},
   "source": [
    "Some common things you would want to do with a logistic regression function would be: \n",
    "1. Fit your training data \n",
    "2. See model performance statistics, like a confusion matrix and accuracy score \n",
    "3. Predict outcome variable for test set \n",
    "\n",
    "How easy are each of these tasks with the library? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf5417b",
   "metadata": {},
   "source": [
    "## 2. Logistic regression with sklearn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "98f2550f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected 2D array, got 1D array instead:\n",
      "array=[10.38 17.77 21.25 20.38 14.34 15.7  19.98 20.83 21.82 24.04 23.24 17.89\n",
      " 24.8  23.95 22.61 27.54 20.13 20.68 22.15 14.36 15.71 12.44 14.26 23.04\n",
      " 21.38 16.4  21.53 20.25 25.27 15.05 25.11 18.7  23.98 26.47 17.88 21.59\n",
      " 21.72 18.42 25.2  20.82 21.58 21.35 24.81 20.28 21.81 17.6  16.84 18.66\n",
      " 14.63 22.3  21.6  16.34 18.24 18.7  22.02 18.75 18.57 21.59 19.31 11.79\n",
      " 14.88 20.98 22.15 13.86 23.84 23.94 21.01 19.04 17.33 16.49 21.31 14.64\n",
      " 24.52 15.79 16.52 19.65 10.94 16.15 23.97 18.   20.97 15.86 24.91 26.29\n",
      " 15.65 18.52 21.46 24.59 21.8  15.24 24.02 22.76 14.76 18.3  19.83 23.03\n",
      " 17.84 19.94 12.84 19.77 24.98 13.43 20.52 19.4  19.29 15.56 18.33 18.54\n",
      " 19.67 21.26 16.99 20.76 19.65 20.19 15.83 21.53 15.76 16.67 22.91 20.01\n",
      " 10.82 17.12 20.2  10.89 16.39 17.21 24.69 18.91 16.39 25.12 13.29 19.48\n",
      " 21.54 13.93 21.91 22.47 16.67 15.39 17.57 13.39 11.97 18.05 17.31 15.92\n",
      " 14.97 14.65 16.58 18.77 15.18 17.91 20.78 20.7  15.34 13.08 15.34 17.94\n",
      " 20.74 19.46 12.74 12.96 20.18 15.94 18.15 22.22 22.04 19.76  9.71 18.8\n",
      " 24.68 16.95 12.39 19.63 11.89 14.71 15.15 14.45 18.06 20.11 22.22 13.06\n",
      " 21.87 26.57 20.31 14.92 22.41 15.11 18.58 17.19 17.39 15.9  23.12 21.41\n",
      " 18.22 26.86 23.21 16.33 22.29 21.84 22.49 20.22 19.56 19.32 26.67 23.75\n",
      " 18.6  16.68 17.27 20.26 22.54 12.91 22.14 18.94 18.47 25.56 23.81 16.93\n",
      " 18.35 17.48 21.56 32.47 13.16 13.9  17.53 20.25 17.02 13.47 15.46 15.51\n",
      " 23.97 22.33 19.08 27.08 33.81 27.81 15.91 21.25 26.97 21.46 27.85 39.28\n",
      " 15.6  15.04 18.19 23.77 23.5  19.86 17.43 14.11 25.22 14.93 23.56 18.45\n",
      " 19.82 17.08 19.33 17.05 28.77 17.27 23.2  33.56 27.06 23.06 22.13 19.38\n",
      " 22.07 31.12 18.95 21.84 16.21 20.39 16.82 13.04 20.99 15.67 24.48 17.36\n",
      " 14.16 19.98 17.84 15.18 26.6  14.02 18.18 18.77 15.7  18.4  20.76 13.12\n",
      " 19.96 18.89 19.73 19.1  16.02 17.46 13.78 13.27 12.35 18.14 18.17 23.09\n",
      " 18.9  19.89 23.86 18.61 18.16 24.49 15.82 14.4  12.71 13.84 19.11 15.69\n",
      " 13.37 10.72 18.6  16.85 14.08 18.87 18.9  17.   16.18 19.66 13.32 21.51\n",
      " 15.21 17.3  12.88 17.93 20.71 21.88 15.51 19.35 19.86 14.78 19.02 21.\n",
      " 14.23 21.43 17.53 24.27 16.54 16.84 14.96 21.68 15.45 14.71 18.9  14.74\n",
      " 16.03 14.96 17.07 19.22 17.46 25.74 14.07 19.07 18.59 16.21 15.49 18.32\n",
      " 18.07 21.57 18.84 18.29 16.95 21.78 26.83 18.02 17.25 21.9  23.29 13.21\n",
      " 15.1  17.35 16.07 16.07 20.22 28.21 15.15 18.83 12.96 14.93 22.72 17.48\n",
      " 13.72 23.29 14.09 16.16 15.5  23.21 12.22 16.84 19.97 22.28 17.72 17.18\n",
      " 18.89 17.46 14.83 17.26 21.02 10.91 18.29 16.17 14.95 18.59 14.86 21.37\n",
      " 20.66 17.92 17.57 16.83 21.68 22.11 29.81 21.17 21.7  21.08 12.17 21.41\n",
      " 19.04 13.98 16.02 19.13 19.12 21.28 14.98 21.98 16.62 17.67 22.53 17.68\n",
      " 19.54 21.97 16.94 19.62 19.54 15.98 19.6  15.66 17.2  25.42 15.79 18.32\n",
      " 16.85 24.89 28.03 17.66 19.34 20.52 21.54 25.   28.23 13.98 17.15 30.72\n",
      " 29.29 25.25 25.13 28.2  27.15 26.27 26.99 18.36 18.22 20.13 20.74 18.1\n",
      " 23.33 18.18 18.49 28.14 14.93 29.97 15.62 15.73 20.53 16.62 14.59 19.51\n",
      " 18.03 19.24 14.06 17.64 11.28 16.41 16.85 18.82 16.17 20.2  22.44 13.23\n",
      " 20.56 12.83 20.54 20.21 18.17 17.31 17.52 21.24 16.74 24.49 16.32 19.83\n",
      " 12.87 13.14 20.04 17.12 15.7  23.95 14.69 14.7  20.52 13.66 19.07 18.61\n",
      " 20.58 20.26 18.22 16.7  13.9  21.6  19.83 18.68 15.68 13.1  18.75 12.27\n",
      " 13.17 13.44 17.56 20.02 16.33 20.67 17.62 20.86 22.55 24.44 25.49 25.44\n",
      " 14.44 24.99 25.42 28.06 20.7  23.23 16.35 16.58 19.34 24.21 21.48 22.44\n",
      " 29.43 21.94 28.92 27.61 19.59 27.88 22.68 23.93 27.15 29.37 30.62 25.09\n",
      " 22.39 28.25 28.08 29.33 24.54].\n",
      "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n"
     ]
    }
   ],
   "source": [
    "try: \n",
    "    clf = LogisticRegression(random_state=0).fit(mean_radius, y)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a95dba7e",
   "metadata": {},
   "source": [
    "I found it interesting that you have to have 2D array of input variables. It cannot handle a 1D numpy case gracefully, and throws an exception. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "5394786a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 1)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_radius = mean_radius.reshape(-1, 1)\n",
    "mean_radius.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "30ecf18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(random_state=0).fit(mean_radius, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "0b86a63f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7047451669595782"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ACCURACY\n",
    "# There are two ways of calculating model accuracy - \n",
    "# a built in class attribute...\n",
    "clf.score(mean_radius, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "411df5ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7047451669595782"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ... or a helper function. \n",
    "preds = clf.predict(mean_radius)\n",
    "accuracy_score(y, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "40ac0902",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 91, 121],\n",
       "       [ 47, 310]])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CONFUSION MATRIX\n",
    "confusion_matrix(y, preds) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6022007",
   "metadata": {},
   "source": [
    "Two thoughts here are: \n",
    "1. It's not immediately clear what the rows/columns of the confusion matrix mean, and \n",
    "2. It would be nice to have all model performance statistics as attributes on the LogisticRegression class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "d596dbe1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1,\n",
       "       1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1,\n",
       "       1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0,\n",
       "       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0,\n",
       "       1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1,\n",
       "       1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1,\n",
       "       0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
       "       1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1,\n",
       "       1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "       1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "       1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0,\n",
       "       1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PREDICT OUTCOME VARIABLE \n",
    "clf.predict(mean_radius)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf6829a0",
   "metadata": {},
   "source": [
    "## 3. Logistic regression with statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "b314a496",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nCONFUSED ATTEMPT AT TRAINING: API changed!\\n\\nmean_radius.reshape(-1).shape\\n\\n# Create the formula string \\nformula = \"Target ~ mean_radius\"\\nmean_radius = mean_radius.reshape(-1)\\ntrainingdata = pd.DataFrame({\\n    \\'Target\\': y,\\n    \\'mean_radius\\': mean_radius\\n})\\n\\ntrainingdata.head()\\n\\nThis method of specifying a formula call, like in R, is now available through the attribute \\nLogit.from_formula()\\n'"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "CONFUSED ATTEMPT AT TRAINING: API changed!\n",
    "\n",
    "mean_radius.reshape(-1).shape\n",
    "\n",
    "# Create the formula string \n",
    "formula = \"Target ~ mean_radius\"\n",
    "mean_radius = mean_radius.reshape(-1)\n",
    "trainingdata = pd.DataFrame({\n",
    "    'Target': y,\n",
    "    'mean_radius': mean_radius\n",
    "})\n",
    "\n",
    "trainingdata.head()\n",
    "\n",
    "This method of specifying a formula call, like in R, is now available through the attribute \n",
    "Logit.from_formula()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "b2c45759",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.680047\n",
      "         Iterations 4\n"
     ]
    }
   ],
   "source": [
    "# Build the model\n",
    "clf = Logit(y, mean_radius).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "c0525a51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.54274549, 0.57283519, 0.58683384, 0.58334638, 0.55892246])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PREDICTIONS\n",
    "# If you want to pass a different outcome vector (such as a test set), you can, \n",
    "# but by default the class will use the outcome vector you used at train time. \n",
    "preds = clf.predict()\n",
    "preds[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "9f7b1c8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'LogitResults' object has no attribute 'score'\n"
     ]
    }
   ],
   "source": [
    "# ACCURACY SCORE\n",
    "try:\n",
    "    clf.score()\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca4a1b9b",
   "metadata": {},
   "source": [
    "It was confusing from [the documentation](https://www.statsmodels.org/stable/generated/statsmodels.discrete.discrete_model.Logit.score.html#statsmodels.discrete.discrete_model.Logit.score) how we were supposed to pull the accuracy score. We were not sure where to pull the \"params\" argument from, or what that meant. [the documentation for the main Logit class](https://www.statsmodels.org/stable/generated/statsmodels.discrete.discrete_model.Logit.html#statsmodels.discrete.discrete_model.Logit) did not specify that \"params\" was an attribute of the trained model object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "124e0a3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score() missing 1 required positional argument: 'params'\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    Logit(y, mean_radius).score()\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "fd0eb8b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01651256])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "e3473dee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.547473508864641e-13"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Logit(y, mean_radius).score(clf.params)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59785bec",
   "metadata": {},
   "source": [
    "The documentation for the \"score\" was difficult to understand. It was targeted to an audience with an advanced statistics background. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "cbf821f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0., 212.],\n",
       "       [  0., 357.]])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CONFUSION MATRIX\n",
    "clf.pred_table()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252695df",
   "metadata": {},
   "source": [
    "One thing we noticed while building this model is that the model API has changed over time. This [blog post](https://data.library.virginia.edu/logistic-regression-four-ways-with-python/) has a pretty different specification for the logistic regression call, which is closer to R syntax (specifying a formula string). The [new documentation](https://www.statsmodels.org/stable/generated/statsmodels.discrete.discrete_model.Logit.html#statsmodels.discrete.discrete_model.Logit) is closer to scikit-learn where you just specify an array of predictor and outcome variables. \n",
    "\n",
    "One thing we didn't like was that the new API documentation didn't have examples of how to set up the model. We were not sure if we needed to call \".fit()\" to train the model. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf3931c5",
   "metadata": {},
   "source": [
    "## 4. Package performance \n",
    "Time the model training for each package and see if there is a computational difference. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "8c0f6dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "8b24b8ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sklearn model trained in 0.0377 seconds.\n"
     ]
    }
   ],
   "source": [
    "# sklearn\n",
    "tic = time.perf_counter()\n",
    "LogisticRegression(random_state=0).fit(mean_radius, y)\n",
    "toc = time.perf_counter()\n",
    "\n",
    "print(f\"Sklearn model trained in {toc - tic:0.4f} seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "0eb150ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.680047\n",
      "         Iterations 4\n",
      "Statsmodels model trained in 0.0090 seconds.\n"
     ]
    }
   ],
   "source": [
    "# statsmodels\n",
    "tic = time.perf_counter()\n",
    "Logit(y, mean_radius).fit()\n",
    "toc = time.perf_counter()\n",
    "\n",
    "print(f\"Statsmodels model trained in {toc - tic:0.4f} seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e89e71d",
   "metadata": {},
   "source": [
    "Scale this up to train the model 10x and better protect against random state of your machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "59304d41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sklearn model trained in 0.1858 seconds.\n"
     ]
    }
   ],
   "source": [
    "# sklearn\n",
    "tic = time.perf_counter()\n",
    "for i in range(10):\n",
    "    LogisticRegression(random_state=0).fit(mean_radius, y)\n",
    "toc = time.perf_counter()\n",
    "\n",
    "print(f\"Sklearn model trained in {toc - tic:0.4f} seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "f3ca5b06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.680047\n",
      "         Iterations 4\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.680047\n",
      "         Iterations 4\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.680047\n",
      "         Iterations 4\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.680047\n",
      "         Iterations 4\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.680047\n",
      "         Iterations 4\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.680047\n",
      "         Iterations 4\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.680047\n",
      "         Iterations 4\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.680047\n",
      "         Iterations 4\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.680047\n",
      "         Iterations 4\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.680047\n",
      "         Iterations 4\n",
      "Statsmodels model trained in 0.0790 seconds.\n"
     ]
    }
   ],
   "source": [
    "# statsmodels\n",
    "tic = time.perf_counter()\n",
    "for i in range(10):\n",
    "    Logit(y, mean_radius).fit()\n",
    "toc = time.perf_counter()\n",
    "\n",
    "print(f\"Statsmodels model trained in {toc - tic:0.4f} seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d85dd89c",
   "metadata": {},
   "source": [
    "Finding - statsmodels is faster in model training. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b18c1b8",
   "metadata": {},
   "source": [
    "## 5. Summary\n",
    "\n",
    "1. We were more impressed with scikit-learn's documentation and examples. \n",
    "2. Both packages could easily perform the regression we're planning. \n",
    "3. Statsmodels did train a little faster than scikit-learn. \n",
    "\n",
    "For our project, because we don't have a very computationally-intensive model, we will likely go with scikit-learn. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
